---
title: "Pagination & Delta Queries"
description: "Handle large datasets with cursors and incremental queries"
---

Query API responses can contain thousands of records. Use pagination to retrieve data in manageable chunks, and delta queries to fetch only new data since your last sync.

## Cursor-based pagination

Every response includes a `cursor` for fetching the next page:

```json
{
  "data": [...],
  "cursor": "eyJsYXN0X2lkIjogMTIzNH0=",
  "has_more": true
}
```

Pass the cursor to get the next page:

<CodeGroup>

```typescript TypeScript
async function fetchAllSearchHistory(uid: string) {
  const allData: SearchEntry[] = [];
  let cursor: string | undefined;

  do {
    const params = new URLSearchParams({ uid });
    if (cursor) {
      params.set('cursor', cursor);
    }

    const response = await fetch(
      `https://query.emergedata.ai/v1/sync/get_search?${params}`,
      { headers: { 'Authorization': `Bearer ${API_TOKEN}` } }
    );

    const result = await response.json();
    allData.push(...result.data);

    cursor = result.has_more ? result.cursor : undefined;
  } while (cursor);

  return allData;
}
```

```python Python
async def fetch_all_search_history(uid: str) -> list[dict]:
    all_data = []
    cursor = None

    while True:
        params = {'uid': uid}
        if cursor:
            params['cursor'] = cursor

        response = requests.get(
            'https://query.emergedata.ai/v1/sync/get_search',
            params=params,
            headers={'Authorization': f'Bearer {API_TOKEN}'}
        )

        result = response.json()
        all_data.extend(result['data'])

        if not result.get('has_more'):
            break
        cursor = result['cursor']

    return all_data
```

</CodeGroup>

## Page size

Control the number of records per page with the `limit` parameter:

```bash
curl 'https://query.emergedata.ai/v1/sync/get_search?uid=user_123&limit=500' \
  -H 'Authorization: Bearer your_api_token'
```

| Parameter | Default | Maximum |
|-----------|---------|---------|
| `limit` | 100 | 1000 |

## Delta queries

Fetch only data that's been ingested since your last sync using `ingested_after`:

```bash
curl 'https://query.emergedata.ai/v1/sync/get_search?uid=user_123&ingested_after=2024-01-15T00:00:00Z' \
  -H 'Authorization: Bearer your_api_token'
```

### Time-based filtering

| Parameter | Description | Format |
|-----------|-------------|--------|
| `ingested_after` | Records ingested after this time | ISO 8601 |
| `ingested_before` | Records ingested before this time | ISO 8601 |

<Note>
`ingested_after` and `ingested_before` filter by when data was added to Emerge, not when the user performed the action. This is useful for incremental syncs.
</Note>

### Delta sync pattern

<CodeGroup>

```typescript TypeScript
interface SyncState {
  lastSyncTime: string;
  lastCursor?: string;
}

async function deltaSync(uid: string, state: SyncState): Promise<SyncState> {
  const newData: SearchEntry[] = [];
  let cursor = state.lastCursor;
  const syncStartTime = new Date().toISOString();

  do {
    const params = new URLSearchParams({
      uid,
      ingested_after: state.lastSyncTime
    });
    if (cursor) {
      params.set('cursor', cursor);
    }

    const response = await fetch(
      `https://query.emergedata.ai/v1/sync/get_search?${params}`,
      { headers: { 'Authorization': `Bearer ${API_TOKEN}` } }
    );

    const result = await response.json();
    newData.push(...result.data);

    cursor = result.has_more ? result.cursor : undefined;
  } while (cursor);

  // Process new data
  await processNewData(newData);

  // Return new state for next sync
  return {
    lastSyncTime: syncStartTime,
    lastCursor: undefined
  };
}

// Usage
let syncState: SyncState = {
  lastSyncTime: '2024-01-01T00:00:00Z'
};

// Run periodically
syncState = await deltaSync('user_123', syncState);
```

```python Python
from dataclasses import dataclass
from datetime import datetime
from typing import Optional

@dataclass
class SyncState:
    last_sync_time: str
    last_cursor: Optional[str] = None


async def delta_sync(uid: str, state: SyncState) -> SyncState:
    new_data = []
    cursor = state.last_cursor
    sync_start_time = datetime.utcnow().isoformat() + 'Z'

    while True:
        params = {
            'uid': uid,
            'ingested_after': state.last_sync_time
        }
        if cursor:
            params['cursor'] = cursor

        response = requests.get(
            'https://query.emergedata.ai/v1/sync/get_search',
            params=params,
            headers={'Authorization': f'Bearer {API_TOKEN}'}
        )

        result = response.json()
        new_data.extend(result['data'])

        if not result.get('has_more'):
            break
        cursor = result['cursor']

    # Process new data
    await process_new_data(new_data)

    # Return new state for next sync
    return SyncState(
        last_sync_time=sync_start_time,
        last_cursor=None
    )


# Usage
sync_state = SyncState(last_sync_time='2024-01-01T00:00:00Z')

# Run periodically
sync_state = await delta_sync('user_123', sync_state)
```

</CodeGroup>

## Best practices

<AccordionGroup>
  <Accordion title="Store sync state">
    Persist the `lastSyncTime` so you can resume delta syncs after restarts.
  </Accordion>
  <Accordion title="Handle empty results">
    An empty `data` array with `has_more: false` means no new data since your last sync.
  </Accordion>
  <Accordion title="Use reasonable page sizes">
    500 records per page balances throughput and memory usage for most applications.
  </Accordion>
  <Accordion title="Implement backoff on errors">
    If you hit rate limits or errors, back off exponentially before retrying.
  </Accordion>
</AccordionGroup>

## Async pagination

For async queries, pagination works the same way. The job result includes a cursor:

```typescript
const result = await fetch(
  `https://query.emergedata.ai/v1/job/${taskId}`,
  { headers: { 'Authorization': `Bearer ${API_TOKEN}` } }
).then(r => r.json());

if (result.status === 'completed') {
  // Use result.cursor for next page
  if (result.cursor) {
    // Fetch next page with new async job
    const nextJob = await fetch(
      `https://query.emergedata.ai/v1/search?uid=${uid}&cursor=${result.cursor}`,
      { headers: { 'Authorization': `Bearer ${API_TOKEN}` } }
    ).then(r => r.json());
  }
}
```
